{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee27818-ec62-40fc-b44b-dc39794e05aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count, sum, min, max, countDistinct, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d27d180-ffeb-410c-aabc-f08aafe5217a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_c0</th><th>date</th><th>serial_number</th><th>model</th><th>capacity_bytes</th><th>failure</th><th>Read_Error_Rate</th><th>Reallocated_Sectors_Count</th><th>Power_On_Hours</th><th>Temperature</th><th>Current_Pending_Sector_Count</th></tr></thead><tbody><tr><td>4329235</td><td>2013-12-03</td><td>6XW05AYQ</td><td>ST31500541AS</td><td>1500301910016</td><td>false</td><td>40572143</td><td>0</td><td>36962</td><td>23</td><td>0</td></tr><tr><td>4329236</td><td>2013-12-03</td><td>WD-WCAWZ0827930</td><td>WDC WD30EZRX</td><td>3000592982016</td><td>false</td><td>0</td><td>0</td><td>12830</td><td>21</td><td>0</td></tr><tr><td>4329237</td><td>2013-12-03</td><td>MJ1311YNG3EJJA</td><td>Hitachi HDS5C3030ALA630</td><td>3000592982016</td><td>false</td><td>0</td><td>0</td><td>18736</td><td>26</td><td>0</td></tr><tr><td>4329238</td><td>2013-12-03</td><td>13H32WEAS</td><td>TOSHIBA DT01ACA300</td><td>3000592982016</td><td>false</td><td>0</td><td>0</td><td>5313</td><td>30</td><td>0</td></tr><tr><td>4329239</td><td>2013-12-03</td><td>PL1321LAG31Y7H</td><td>Hitachi HDS5C4040ALE630</td><td>4000787030016</td><td>false</td><td>0</td><td>0</td><td>6460</td><td>23</td><td>0</td></tr><tr><td>4329240</td><td>2013-12-03</td><td>6XW05YMX</td><td>ST31500541AS</td><td>1500301910016</td><td>false</td><td>83783737</td><td>0</td><td>36962</td><td>24</td><td>0</td></tr><tr><td>4329241</td><td>2013-12-03</td><td>MK0311YHG9JPAA</td><td>Hitachi HDS723030ALA640</td><td>3000592982016</td><td>false</td><td>131077</td><td>17</td><td>16826</td><td>28</td><td>0</td></tr><tr><td>4329242</td><td>2013-12-03</td><td>MJ1311YNG6KX6A</td><td>Hitachi HDS5C3030ALA630</td><td>3000592982016</td><td>false</td><td>0</td><td>0</td><td>14493</td><td>23</td><td>0</td></tr><tr><td>4329243</td><td>2013-12-03</td><td>Z300CR9R</td><td>ST4000DM000</td><td>4000787030016</td><td>false</td><td>24949392</td><td>0</td><td>2651</td><td>20</td><td>0</td></tr><tr><td>4329244</td><td>2013-12-03</td><td>W300B2TV</td><td>ST4000DM000</td><td>4000787030016</td><td>false</td><td>60690512</td><td>0</td><td>3395</td><td>17</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4329235,
         "2013-12-03",
         "6XW05AYQ",
         "ST31500541AS",
         1500301910016,
         false,
         40572143,
         0,
         36962,
         23,
         0
        ],
        [
         4329236,
         "2013-12-03",
         "WD-WCAWZ0827930",
         "WDC WD30EZRX",
         3000592982016,
         false,
         0,
         0,
         12830,
         21,
         0
        ],
        [
         4329237,
         "2013-12-03",
         "MJ1311YNG3EJJA",
         "Hitachi HDS5C3030ALA630",
         3000592982016,
         false,
         0,
         0,
         18736,
         26,
         0
        ],
        [
         4329238,
         "2013-12-03",
         "13H32WEAS",
         "TOSHIBA DT01ACA300",
         3000592982016,
         false,
         0,
         0,
         5313,
         30,
         0
        ],
        [
         4329239,
         "2013-12-03",
         "PL1321LAG31Y7H",
         "Hitachi HDS5C4040ALE630",
         4000787030016,
         false,
         0,
         0,
         6460,
         23,
         0
        ],
        [
         4329240,
         "2013-12-03",
         "6XW05YMX",
         "ST31500541AS",
         1500301910016,
         false,
         83783737,
         0,
         36962,
         24,
         0
        ],
        [
         4329241,
         "2013-12-03",
         "MK0311YHG9JPAA",
         "Hitachi HDS723030ALA640",
         3000592982016,
         false,
         131077,
         17,
         16826,
         28,
         0
        ],
        [
         4329242,
         "2013-12-03",
         "MJ1311YNG6KX6A",
         "Hitachi HDS5C3030ALA630",
         3000592982016,
         false,
         0,
         0,
         14493,
         23,
         0
        ],
        [
         4329243,
         "2013-12-03",
         "Z300CR9R",
         "ST4000DM000",
         4000787030016,
         false,
         24949392,
         0,
         2651,
         20,
         0
        ],
        [
         4329244,
         "2013-12-03",
         "W300B2TV",
         "ST4000DM000",
         4000787030016,
         false,
         60690512,
         0,
         3395,
         17,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_c0",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "serial_number",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "model",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "capacity_bytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "failure",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "Read_Error_Rate",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Reallocated_Sectors_Count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Power_On_Hours",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Temperature",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Current_Pending_Sector_Count",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nome da database e tabela\n",
    "database_name = \"PRATA\"\n",
    "table_name = \"2013_hard_drive_csv_parquet_prata\"\n",
    "\n",
    "df = spark.table(f\"{database_name}.{table_name}\")\n",
    "df.limit(10).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36027e8d-aa81-4557-bc9f-a553ae4c1f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Os servidores são confiáveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3808ad-ee59-404b-a445-35e3c58a15fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n|failure|  count|\n+-------+-------+\n|   true|    724|\n|  false|5090777|\n+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupar pela coluna 'failure' e contar as ocorrências\n",
    "result_failure = df.groupBy(\"failure\").count()\n",
    "result_failure.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adcba1b1-4c25-41f0-a3f9-23d6fb9848aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No contexto da confiabildiade dos servidores, pela diferença entre a quantidade de falhas e de não falhas, se pode ver que os servidores são equipamentos com baixa taxa de falha e alta disponibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa1e9c72-d473-4afd-be72-6ef1d343bcf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Realizando as filtragens para trabalhar somente com as falhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae10b749-966c-4aa0-9191-01544b7ba51c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtrar os valores 'failure' com valor True\n",
    "df_filtered = df.filter(df[\"failure\"] == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce84395d-3a08-461f-bd08-491bb544ab17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Quais os modelos que mais falham?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "861f26d8-c8ec-4cb2-9841-1768f6d04ee7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n|               model|count|\n+--------------------+-----+\n|         ST3000DM001|  254|\n|        ST31500541AS|  123|\n|        ST31500341AS|   91|\n|         ST1500DL003|   51|\n|         ST4000DM000|   48|\n|Hitachi HDS722020...|   28|\n|Hitachi HDS5C3030...|   26|\n|Hitachi HDS5C4040...|   23|\n|        WDC WD30EZRX|   14|\n|        ST32000542AS|   14|\n|        ST33000651AS|   12|\n|        WDC WD10EADS|   12|\n|         ST2000DL003|    7|\n|Hitachi HDS723030...|    6|\n|         ST2000DL001|    4|\n|        WDC WD30EFRX|    4|\n|  TOSHIBA DT01ACA300|    2|\n|        ST320005XXXX|    1|\n|Hitachi HDS723020...|    1|\n|HGST HMS5C4040ALE640|    1|\n+--------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupar pela coluna modelo e contar as ocorrências\n",
    "result_model = df_filtered.groupBy(\"model\").count().orderBy(\"count\", ascending=False)\n",
    "result_model.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99deb8a0-0394-4c87-b142-cce56afe2739",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "No resultado vemos o modelo com mais falhas no período analisado, evidente que para se ter mais credibilidade na análise um levantamento de mais dados levando em conta quantiades seria necessária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ddae2b-0cde-4f8c-90ff-4184dffe4ac6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Qual a distribuição de itens em relação aos modelos de servidores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff511e5f-d6c4-479e-9c09-42c7dd88bd0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------------+\n|               model|distinct_serial_number_count|\n+--------------------+----------------------------+\n|         ST4000DM000|                        5525|\n|Hitachi HDS722020...|                        4753|\n|         ST3000DM001|                        4658|\n|Hitachi HDS5C3030...|                        4621|\n|Hitachi HDS5C4040...|                        2703|\n|        ST31500541AS|                        2187|\n|Hitachi HDS723030...|                        1034|\n|        ST31500341AS|                         785|\n|        WDC WD10EADS|                         550|\n|        WDC WD30EZRX|                         489|\n|        ST32000542AS|                         381|\n|        WDC WD30EFRX|                         355|\n|        ST33000651AS|                         309|\n|         ST4000DX000|                         180|\n|         ST1500DL003|                         116|\n|        WDC WD10EACS|                         109|\n|  TOSHIBA DT01ACA300|                          60|\n|HGST HMS5C4040ALE640|                          48|\n|HGST HDS724040ALE640|                          42|\n|        WDC WD10EADX|                          20|\n+--------------------+----------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupar pela coluna modelo e contar os diferentes serial_number\n",
    "result_model_p_serial = df.groupBy(\"model\").agg(countDistinct(\"serial_number\").alias(\"distinct_serial_number_count\")).orderBy(\"distinct_serial_number_count\", ascending=False)\n",
    "\n",
    "result_model_p_serial.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049fe2a8-d28f-41e6-b702-aedd34e79058",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Alguns modelos de discos rígidos, como o ST4000DM000, Hitachi HDS722020ALA330, e ST3000DM001, têm um número significativamente maior de serial_number distintos, indicando que esses modelos são amplamente utilizados.\n",
    "Por outro lado, modelos como o WDC WD10EADX e HGST HDS724040ALE640 têm um número muito menor de serial_number distintos, sugerindo que esses modelos são menos comuns.\n",
    "A tabela mostra que modelos das marcas Seagate (ST) e Hitachi são muito populares, com múltiplos modelos listados e um grande número de serial_number distintos.\n",
    "Modelos da Western Digital (WDC) também aparecem na lista, mas com um menor número de serial_number distintos em comparação com Seagate e Hitachi.\n",
    "A presença de diferentes modelos com variados números de serial_number distintos sugere que existe uma variedade de capacidades e tipos de discos rígidos. Por exemplo, modelos com alta capacidade de armazenamento podem ter um número maior de serial_number distintos devido à sua popularidade em ambientes de grandes volumes de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81c14421-64a9-4fbf-8267-81b0f833d4a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Considerando o ano de 2013 dos dados, em quais meses mais falhas ocorrem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fe1ebde-a9f1-4126-966b-d77f0068f9f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n|month|failure_count|\n+-----+-------------+\n|   12|          131|\n|   11|          124|\n|    5|          119|\n|    7|          104|\n|    6|           81|\n|   10|           69|\n|    8|           49|\n|    4|           43|\n|    9|            4|\n+-----+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Adicionar colunas de mês\n",
    "df_filtered = df_filtered.withColumn(\"month\", month(\"date\"))\n",
    "\n",
    "# Agrupar pelas colunas 'month' e contar as ocorrências de 'failure'\n",
    "result_failure_p_month = df_filtered.groupBy(\"month\").agg(count(\"failure\").alias(\"failure_count\")).orderBy(\"failure_count\", ascending = False)\n",
    "\n",
    "# Mostrar os resultados\n",
    "result_failure_p_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ddd3064-bb6f-4c0c-8ce1-45329a1f7ce7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Na questão de falha em relação ao mês, se nota que os dois últimos meses do ano possuem maior concentração de falhas. Com valores semelhantes se tem os meses 5 e 7, uma análise relacionada aos fatores climáticos e de utilização dos mesmo, seria interessante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928d0daa-7ff2-494d-a073-9950e735e545",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n|Temperature|count|\n+-----------+-----+\n|         23|   93|\n|         22|   80|\n|         24|   76|\n|         25|   65|\n|         26|   64|\n|         21|   57|\n|         27|   54|\n|         20|   43|\n|         28|   40|\n|         19|   39|\n|         29|   36|\n|         30|   18|\n|         18|   17|\n|         17|   12|\n|         31|    8|\n|         32|    7|\n|         33|    5|\n|         34|    3|\n|         36|    3|\n|         35|    3|\n+-----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Agrupar pela coluna 'Temperature' e contar os valores 'failure' com valor True\n",
    "result = df_filtered.groupBy(\"Temperature\").count().orderBy(\"count\", ascending = False)\n",
    "\n",
    "# Mostrar os resultados\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "728a1ab2-a985-4409-b0f1-76293fbf3d3f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ao contrário do que seris esperado não são em temperaturas mais altas a maior ocorrência de falhas. Na faixa dos 20 e 30 graus se encontram a maioria das falhas, mais informações seriam necesárias para identificar a razão dessa concentração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ceaebf2-68e5-467e-85cf-56931faec57a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A utilização do Apache Spark para a análise dos dados de discos rígidos mostrou-se extremamente vantajosa, especialmente ao considerar a capacidade de processamento de grandes volumes de informações. Em uma sprint anterior, devido às limitações da plataforma utilizada, foi possível trabalhar apenas com uma versão reduzida deste dataset. No entanto, com o uso do Spark, foi possível carregar e analisar um volume de dados significativamente maior, permitindo uma análise mais abrangente e detalhada.\n",
    "\n",
    "Os resultados obtidos até o momento indicam a popularidade e a distribuição dos diferentes modelos de discos rígidos, bem como a variedade de capacidades disponíveis. Modelos como ST3000DM001, ST31500541AS e ST4000DM000 destacaram-se por possuírem um grande número de ocorrências e serial_number distintos, sugerindo uma alta demanda e utilização desses modelos. Por outro lado, modelos com um menor número de ocorrências, como HGST HMS5C4040ALE640 e Hitachi HDS723020BLA642, podem ser considerados de nicho ou potencialmente descontinuados.\n",
    "\n",
    "Para uma análise mais aprofundada e conclusões assertivas sobre os modelos e sazonalidades, seria necessário dispor de informações adicionais, como dados temporais, taxas de falhas e detalhes de uso. Esses dados complementares permitiriam identificar tendências ao longo do tempo, analisar a confiabilidade dos modelos e fornecer insights sobre os segmentos de mercado atendidos por cada fabricante.\n",
    "\n",
    "O uso das ferramentas e aprendizados adquiridos durante este trabalho tem um imenso potencial de aplicação na atividade profissional. A simplicidade e a eficiência do Spark permitirão avanços significativos na análise de grandes volumes de dados, oferecendo uma base sólida para a tomada de decisões informadas e estratégicas.\n",
    "\n",
    "Em resumo, a capacidade do Spark de lidar com grandes quantidades de dados de forma eficiente abre novas possibilidades para análises detalhadas e abrangentes, contribuindo significativamente para a melhoria contínua dos processos e resultados organizacionais\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "OURO",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
